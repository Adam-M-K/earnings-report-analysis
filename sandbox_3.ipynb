{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import yfinance as yf\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os\n",
    "import openpyxl\n",
    "from sec_cik_mapper import StockMapper\n",
    "from datetime import datetime, timedelta\n",
    "from urllib.parse import urljoin\n",
    "from alpha_vantage.timeseries import TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam Krupa\\OneDrive\\Pulpit\\Investing\\earnings-report-analysis\n"
     ]
    }
   ],
   "source": [
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Resolve the parent directories\n",
    "project_general_path = Path(current_dir).resolve()\n",
    "print(project_general_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tickers():\n",
    "    # URL of the website containing the S&P 500 tickers\n",
    "    url = 'https://www.slickcharts.com/sp500'\n",
    "\n",
    "    # Fetch the page content with headers to avoid being blocked\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36'\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        table = soup.find('table', {'class': 'table table-hover table-borderless table-sm'})\n",
    "        tickers = []\n",
    "        \n",
    "        # Extract tickers from the table\n",
    "        if table:\n",
    "            for row in table.find('tbody').find_all('tr'):\n",
    "                columns = row.find_all('td')\n",
    "                ticker = columns[2].text.strip()  # The third column contains the ticker symbol\n",
    "                tickers.append(ticker)\n",
    "        else:\n",
    "            print(\"Table not found in the page\")\n",
    "    else:\n",
    "        print(\"Failed to fetch S&P 500 tickers\")\n",
    "        tickers = []\n",
    "\n",
    "    return tickers\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates(tickers):\n",
    "    # Initialize an empty DataFrame to store valid earnings data\n",
    "    data = pd.DataFrame(columns=['Ticker', 'Date'])\n",
    "\n",
    "    # Loop through each stock ticker\n",
    "    for ticker_symbol in tickers:\n",
    "        ticker = yf.Ticker(ticker_symbol)\n",
    "        # Fetch the earnings history (past earnings reports)\n",
    "        earnings_history = ticker.earnings_dates\n",
    "        \n",
    "        # Skip if no earnings data is available\n",
    "        if earnings_history is None:\n",
    "            print(f\"{ticker_symbol}: possibly delisted; no earnings dates found\")\n",
    "            continue\n",
    "\n",
    "        # Iterate through each earnings report and determine the correct date classification\n",
    "        for index, row in earnings_history.iterrows():\n",
    "            report_time = pd.to_datetime(row.name)  # Access the index (which is the earnings date) and convert it to datetime\n",
    "            # if report_time.hour >= 16:  # After 4 PM, classify as next day because the trade based on this knowledge can effectively only be executed the day after\n",
    "            #     adjusted_date = (report_time + pd.Timedelta(days=1)).date()\n",
    "            # else:  # Otherwise, use the same day\n",
    "            #     adjusted_date = report_time.date()\n",
    "\n",
    "            # Add each adjusted earnings date as a separate row in the DataFrame\n",
    "            new_row = {'Ticker': ticker_symbol, 'Date': report_time}\n",
    "            data = pd.concat([data, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_stock_prices(data, api_key):\n",
    "    # Initialize the TimeSeries object with your API key\n",
    "    ts = TimeSeries(key=api_key, output_format='pandas')\n",
    "\n",
    "    # Function to fetch and filter stock prices for a given ticker and date\n",
    "    def get_prices(ticker, target_date):\n",
    "        # Fetch daily stock prices\n",
    "        try:\n",
    "            stock_data, _ = ts.get_daily(symbol=ticker, outputsize='full')\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {ticker}: {e}\")\n",
    "            return {}\n",
    "\n",
    "        # Ensure the index is in datetime format\n",
    "        stock_data.index = pd.to_datetime(stock_data.index)\n",
    "\n",
    "        # Define the date range\n",
    "        start_date = target_date - timedelta(days=60)\n",
    "        end_date = target_date + timedelta(days=30)\n",
    "\n",
    "        # Filter the data for the specified date range\n",
    "        filtered_data = stock_data.loc[start_date:end_date]\n",
    "\n",
    "        # Convert the filtered data to a dictionary with dates as keys and closing prices as values\n",
    "        price_dict = filtered_data['4. close'].to_dict()\n",
    "\n",
    "        return price_dict\n",
    "\n",
    "    # Apply the function to each row in the DataFrame\n",
    "    data['Prices'] = data.apply(lambda row: get_prices(row['Ticker'], pd.to_datetime(row['Date'])), axis=1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_prices_alpha_vantage(data, api_key):\n",
    "    # Initialize the TimeSeries object with your API key\n",
    "    ts = TimeSeries(key=api_key, output_format='pandas')\n",
    "\n",
    "    # Function to fetch and filter stock prices for a given ticker and date\n",
    "    def get_prices(ticker, target_date):\n",
    "        # Ensure target_date is timezone-naive\n",
    "        target_date = pd.to_datetime(target_date).tz_localize(None)\n",
    "\n",
    "        # Fetch daily stock prices\n",
    "        try:\n",
    "            stock_data, _ = ts.get_daily(symbol=ticker, outputsize='full')\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {ticker}: {e}\")\n",
    "            return {}\n",
    "\n",
    "        # Ensure the index is in datetime format and timezone-naive\n",
    "        stock_data.index = pd.to_datetime(stock_data.index).tz_localize(None)\n",
    "\n",
    "        # Define the date range\n",
    "        start_date = target_date - timedelta(days=60)\n",
    "        end_date = target_date + timedelta(days=30)\n",
    "\n",
    "        # Filter the data for the specified date range\n",
    "        filtered_data = stock_data.loc[start_date:end_date]\n",
    "\n",
    "        # Convert the filtered data to a dictionary with dates as keys and closing prices as values\n",
    "        price_dict = filtered_data['4. close'].to_dict()\n",
    "\n",
    "        return price_dict\n",
    "\n",
    "    # Apply the function to each row in the DataFrame\n",
    "    data['Prices'] = data.apply(\n",
    "        lambda row: get_prices(row['Ticker'], row['Date']), axis=1\n",
    "    )\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_prices_yahoo(data):\n",
    "    # Function to fetch and filter stock prices for a given ticker and date\n",
    "    def get_prices(ticker, target_date):\n",
    "        # Ensure target_date is in datetime format\n",
    "        target_date = pd.to_datetime(target_date)\n",
    "\n",
    "        # Define the date range\n",
    "        start_date = target_date - timedelta(days=60)\n",
    "        end_date = target_date + timedelta(days=30)\n",
    "\n",
    "        # Ensure end_date and today are of compatible types for comparison\n",
    "        if isinstance(end_date, pd.Timestamp):\n",
    "            end_date = end_date.to_pydatetime()\n",
    "\n",
    "        end_date_date = end_date.date()\n",
    "        today_date = datetime.now().date()\n",
    "\n",
    "        # Fetch historical stock prices using Yahoo Finance\n",
    "        if end_date_date <= today_date: # Check date compatibility explicitly\n",
    "            try:\n",
    "                stock_data = yf.download(ticker, start=start_date, end=end_date).round(3)\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching data for {ticker}: {e}\")\n",
    "                return {}\n",
    "        else:\n",
    "            return {}  # Return an empty dictionary if the end date is in the future\n",
    "    \n",
    "        # Convert the filtered data to a dictionary with dates as keys and closing prices as values\n",
    "        price_dict = stock_data['Close'].to_dict()\n",
    "\n",
    "        return price_dict\n",
    "\n",
    "    # Apply the function to each row in the DataFrame\n",
    "    data['Prices'] = data.apply(\n",
    "        lambda row: get_prices(row['Ticker'], row['Date']), axis=1\n",
    "    )\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = get_tickers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_short = tickers[30:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WFC', 'ACN', 'NOW', 'PEP', 'MCD', 'IBM', 'DIS', 'LIN', 'TMO', 'ABT']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam Krupa\\AppData\\Local\\Temp\\ipykernel_52996\\2737740090.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "data = data = get_dates(tickers_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = get_stock_prices_yahoo(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                     {}\n",
       "1                                                     {}\n",
       "2                                                     {}\n",
       "3                                                     {}\n",
       "4                                                     {}\n",
       "5      {'WFC': {2024-08-12 00:00:00: 51.762, 2024-08-...\n",
       "6      {'WFC': {2024-05-13 00:00:00: 60.447, 2024-05-...\n",
       "7      {'WFC': {2024-02-12 00:00:00: 47.995, 2024-02-...\n",
       "8      {'WFC': {2023-11-13 00:00:00: 39.72, 2023-11-1...\n",
       "9      {'WFC': {2023-08-14 00:00:00: 42.237, 2023-08-...\n",
       "10     {'WFC': {2023-05-15 00:00:00: 37.147, 2023-05-...\n",
       "11     {'WFC': {2023-02-13 00:00:00: 45.758, 2023-02-...\n",
       "12                                                    {}\n",
       "13                                                    {}\n",
       "14                                                    {}\n",
       "15                                                    {}\n",
       "16                                                    {}\n",
       "17     {'ACN': {2024-07-29 00:00:00: 324.878, 2024-07...\n",
       "18     {'ACN': {2024-04-22 00:00:00: 314.753, 2024-04...\n",
       "19     {'ACN': {2024-01-22 00:00:00: 362.72, 2024-01-...\n",
       "20     {'ACN': {2023-10-20 00:00:00: 292.301, 2023-10...\n",
       "21     {'ACN': {2023-07-31 00:00:00: 310.059, 2023-08...\n",
       "22     {'ACN': {2023-04-24 00:00:00: 270.754, 2023-04...\n",
       "23     {'ACN': {2023-01-23 00:00:00: 271.728, 2023-01...\n",
       "24                                                    {}\n",
       "25                                                    {}\n",
       "26                                                    {}\n",
       "27                                                    {}\n",
       "28     {'NOW': {2024-08-26 00:00:00: 827.86, 2024-08-...\n",
       "29     {'NOW': {2024-05-28 00:00:00: 728.86, 2024-05-...\n",
       "30     {'NOW': {2024-02-26 00:00:00: 779.66, 2024-02-...\n",
       "31     {'NOW': {2023-11-27 00:00:00: 670.55, 2023-11-...\n",
       "32     {'NOW': {2023-08-28 00:00:00: 568.31, 2023-08-...\n",
       "33     {'NOW': {2023-05-30 00:00:00: 549.12, 2023-05-...\n",
       "34     {'NOW': {2023-02-27 00:00:00: 428.57, 2023-02-...\n",
       "35     {'NOW': {2022-11-28 00:00:00: 401.93, 2022-11-...\n",
       "36                                                    {}\n",
       "37                                                    {}\n",
       "38                                                    {}\n",
       "39                                                    {}\n",
       "40     {'PEP': {2024-08-09 00:00:00: 169.643, 2024-08...\n",
       "41     {'PEP': {2024-05-13 00:00:00: 176.624, 2024-05...\n",
       "42     {'PEP': {2024-02-23 00:00:00: 164.337, 2024-02...\n",
       "43     {'PEP': {2023-12-11 00:00:00: 162.613, 2023-12...\n",
       "44     {'PEP': {2023-08-11 00:00:00: 175.743, 2023-08...\n",
       "45     {'PEP': {2023-05-15 00:00:00: 184.225, 2023-05...\n",
       "46     {'PEP': {2023-02-24 00:00:00: 165.742, 2023-02...\n",
       "47     {'PEP': {2022-12-12 00:00:00: 173.287, 2022-12...\n",
       "48                                                    {}\n",
       "49                                                    {}\n",
       "50                                                    {}\n",
       "51                                                    {}\n",
       "52     {'MCD': {2024-08-30 00:00:00: 285.274, 2024-09...\n",
       "53     {'MCD': {2024-05-30 00:00:00: 247.506, 2024-05...\n",
       "54     {'MCD': {2024-03-01 00:00:00: 285.466, 2024-03...\n",
       "55     {'MCD': {2023-12-07 00:00:00: 280.005, 2023-12...\n",
       "56     {'MCD': {2023-08-31 00:00:00: 272.863, 2023-09...\n",
       "57     {'MCD': {2023-05-30 00:00:00: 273.591, 2023-05...\n",
       "58     {'MCD': {2023-02-24 00:00:00: 251.742, 2023-02...\n",
       "59     {'MCD': {2022-12-02 00:00:00: 261.022, 2022-12...\n",
       "60                                                    {}\n",
       "61                                                    {}\n",
       "62                                                    {}\n",
       "63                                                    {}\n",
       "64     {'IBM': {2024-08-26 00:00:00: 197.98, 2024-08-...\n",
       "65     {'IBM': {2024-05-28 00:00:00: 168.189, 2024-05...\n",
       "66     {'IBM': {2024-02-26 00:00:00: 180.739, 2024-02...\n",
       "67     {'IBM': {2023-11-27 00:00:00: 151.326, 2023-11...\n",
       "68     {'IBM': {2023-08-28 00:00:00: 140.443, 2023-08...\n",
       "69     {'IBM': {2023-05-22 00:00:00: 121.236, 2023-05...\n",
       "70     {'IBM': {2023-02-21 00:00:00: 123.554, 2023-02...\n",
       "71     {'IBM': {2022-11-28 00:00:00: 135.464, 2022-11...\n",
       "72                                                    {}\n",
       "73                                                    {}\n",
       "74                                                    {}\n",
       "75                                                    {}\n",
       "76     {'DIS': {2024-09-16 00:00:00: 91.445, 2024-09-...\n",
       "77     {'DIS': {2024-06-10 00:00:00: 101.817, 2024-06...\n",
       "78     {'DIS': {2024-03-08 00:00:00: 109.329, 2024-03...\n",
       "79     {'DIS': {2023-12-11 00:00:00: 91.372, 2023-12-...\n",
       "80     {'DIS': {2023-09-11 00:00:00: 81.513, 2023-09-...\n",
       "81     {'DIS': {2023-06-12 00:00:00: 92.003, 2023-06-...\n",
       "82     {'DIS': {2023-03-13 00:00:00: 91.47, 2023-03-1...\n",
       "83     {'DIS': {2022-12-12 00:00:00: 93.505, 2022-12-...\n",
       "84     {'LIN': {2024-09-03 00:00:00: 471.231, 2024-09...\n",
       "85     {'LIN': {2024-06-03 00:00:00: 430.365, 2024-06...\n",
       "86     {'LIN': {2024-03-04 00:00:00: 450.11, 2024-03-...\n",
       "87     {'LIN': {2023-12-08 00:00:00: 396.435, 2023-12...\n",
       "88     {'LIN': {2023-08-28 00:00:00: 375.063, 2023-08...\n",
       "89     {'LIN': {2023-05-30 00:00:00: 347.145, 2023-05...\n",
       "90     {'LIN': {2023-02-27 00:00:00: 335.686, 2023-02...\n",
       "91     {'LIN': {2022-12-09 00:00:00: 323.729, 2022-12...\n",
       "92     {'LIN': {2022-08-29 00:00:00: 278.041, 2022-08...\n",
       "93     {'LIN': {2022-05-31 00:00:00: 312.837, 2022-06...\n",
       "94     {'LIN': {2022-02-28 00:00:00: 281.415, 2022-03...\n",
       "95     {'LIN': {2021-12-13 00:00:00: 320.714, 2021-12...\n",
       "96                                                    {}\n",
       "97                                                    {}\n",
       "98                                                    {}\n",
       "99                                                    {}\n",
       "100    {'TMO': {2024-08-26 00:00:00: 604.756, 2024-08...\n",
       "101    {'TMO': {2024-05-28 00:00:00: 571.392, 2024-05...\n",
       "102    {'TMO': {2024-02-26 00:00:00: 561.951, 2024-02...\n",
       "103    {'TMO': {2023-12-04 00:00:00: 493.662, 2023-12...\n",
       "104    {'TMO': {2023-08-28 00:00:00: 542.971, 2023-08...\n",
       "105    {'TMO': {2023-05-30 00:00:00: 511.787, 2023-05...\n",
       "106    {'TMO': {2023-02-27 00:00:00: 538.44, 2023-02-...\n",
       "107    {'TMO': {2022-12-05 00:00:00: 553.924, 2022-12...\n",
       "108                                                   {}\n",
       "109                                                   {}\n",
       "110                                                   {}\n",
       "111                                                   {}\n",
       "112    {'ABT': {2024-08-19 00:00:00: 111.375, 2024-08...\n",
       "113    {'ABT': {2024-05-20 00:00:00: 102.184, 2024-05...\n",
       "114    {'ABT': {2024-02-20 00:00:00: 114.91, 2024-02-...\n",
       "115    {'ABT': {2023-11-27 00:00:00: 100.7, 2023-11-2...\n",
       "116    {'ABT': {2023-08-21 00:00:00: 101.277, 2023-08...\n",
       "117    {'ABT': {2023-05-22 00:00:00: 105.044, 2023-05...\n",
       "118    {'ABT': {2023-02-21 00:00:00: 100.08, 2023-02-...\n",
       "119    {'ABT': {2022-11-28 00:00:00: 101.301, 2022-11...\n",
       "Name: Prices, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set display options to show all rows and columns\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "data['Prices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "earnings-report-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
