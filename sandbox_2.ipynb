{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import yfinance as yf\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os\n",
    "import openpyxl\n",
    "from sec_cik_mapper import StockMapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam Krupa\\OneDrive\\Pulpit\\Investing\\earnings-report-analysis\n"
     ]
    }
   ],
   "source": [
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Resolve the parent directories\n",
    "project_general_path = Path(current_dir).resolve()\n",
    "print(project_general_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tickers():\n",
    "    # URL of the website containing the S&P 500 tickers\n",
    "    url = 'https://www.slickcharts.com/sp500'\n",
    "\n",
    "    # Fetch the page content with headers to avoid being blocked\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36'\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        table = soup.find('table', {'class': 'table table-hover table-borderless table-sm'})\n",
    "        tickers = []\n",
    "        \n",
    "        # Extract tickers from the table\n",
    "        if table:\n",
    "            for row in table.find('tbody').find_all('tr'):\n",
    "                columns = row.find_all('td')\n",
    "                ticker = columns[2].text.strip()  # The third column contains the ticker symbol\n",
    "                tickers.append(ticker)\n",
    "        else:\n",
    "            print(\"Table not found in the page\")\n",
    "    else:\n",
    "        print(\"Failed to fetch S&P 500 tickers\")\n",
    "        tickers = []\n",
    "\n",
    "    return tickers\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = get_tickers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_short = tickers[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates(tickers):\n",
    "    # Initialize an empty DataFrame to store valid earnings data\n",
    "    data = pd.DataFrame(columns=['Ticker', 'Date'])\n",
    "\n",
    "    # Loop through each stock ticker\n",
    "    for ticker_symbol in tickers:\n",
    "        ticker = yf.Ticker(ticker_symbol)\n",
    "        # Fetch the earnings history (past earnings reports)\n",
    "        earnings_history = ticker.earnings_dates\n",
    "        \n",
    "        # Skip if no earnings data is available\n",
    "        if earnings_history is None:\n",
    "            print(f\"{ticker_symbol}: possibly delisted; no earnings dates found\")\n",
    "            continue\n",
    "\n",
    "        # Iterate through each earnings report and determine the correct date classification\n",
    "        for index, row in earnings_history.iterrows():\n",
    "            report_time = pd.to_datetime(row.name)  # Access the index (which is the earnings date) and convert it to datetime\n",
    "            # if report_time.hour >= 16:  # After 4 PM, classify as next day because the trade based on this knowledge can effectively only be executed the day after\n",
    "            #     adjusted_date = (report_time + pd.Timedelta(days=1)).date()\n",
    "            # else:  # Otherwise, use the same day\n",
    "            #     adjusted_date = report_time.date()\n",
    "\n",
    "            # Add each adjusted earnings date as a separate row in the DataFrame\n",
    "            new_row = {'Ticker': ticker_symbol, 'Date': report_time}\n",
    "            data = pd.concat([data, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CIK(data):\n",
    "    mapper = StockMapper()\n",
    "    ticker_to_cik = mapper.ticker_to_cik\n",
    "\n",
    "    # Ensure tickers are in uppercase to match the mapping keys\n",
    "    data['Ticker'] = data['Ticker'].str.upper()\n",
    "\n",
    "    # Map the 'Ticker' column to CIK numbers\n",
    "    data['CIK'] = data['Ticker'].map(ticker_to_cik)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam Krupa\\AppData\\Local\\Temp\\ipykernel_141800\\1265451522.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "data = get_dates(tickers_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ticker                      Date         CIK\n",
      "0    AAPL 2025-10-28 20:00:00-04:00  0000320193\n",
      "1    AAPL 2025-07-29 20:00:00-04:00  0000320193\n",
      "2    AAPL 2025-04-29 20:00:00-04:00  0000320193\n",
      "3    AAPL 2025-01-29 19:00:00-05:00  0000320193\n",
      "4    AAPL 2024-10-30 20:00:00-04:00  0000320193\n",
      "5    AAPL 2024-07-31 20:00:00-04:00  0000320193\n",
      "6    AAPL 2024-05-01 20:00:00-04:00  0000320193\n",
      "7    AAPL 2024-01-31 19:00:00-05:00  0000320193\n",
      "8    AAPL 2023-11-01 20:00:00-04:00  0000320193\n",
      "9    AAPL 2023-08-02 20:00:00-04:00  0000320193\n",
      "10   AAPL 2023-05-03 20:00:00-04:00  0000320193\n",
      "11   AAPL 2023-02-01 19:00:00-05:00  0000320193\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_CIK(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "earnings-report-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
